---
title: Privacy Supreme 2023 - a summary and some thoughts 
feature_text: |
  Some thoughts arising from the discussion 
excerpt: |
  "The changing terminology in policy documents and initiatives can also be indicative of different groups in different eras of the development of technology, using terminologies that suit the purpose of their developmental paradigms."
date: 2023-08-26
---

[The Internet Freedom Foundation](https://internetfreedom.in/donate/) was celebrating six years of the Indian right to privacy judgment in their flagship event "Privacy Supreme" on the 24th of August (this past Thursday). Since I was in Delhi and am researching on the topic of semantics of law, I went there to attend and see what insights I could gain for future readings in an area of interest.

While the initial few thoughts below are more or less a summation of the learned panellists at IFF's event, some of my own thoughts occasionally interweave. I try to contain them towards the end of the session summaries and as separate sections. 

## Table of Contents:

1. [The non-artificial consequences of AI](#session-1), moderated by Shivangi Narayan (researcher at AGOPOL) and Samarth Bansal (Independent journalist, writer, and coder)
2. [Thoughts on how emergent abilities of AI "emerge"](#thoughts-1)
3. ["How public are digital public infrastructures?"](session-2) which was moderated by Aditi Agrawal (independent technology journalist) and the panellists were Mansi Kedia (Senior Fellow at ICRIER), Rohit Kumar (Founding partner at the Quantum Hub), Nikhil Pahwa (Entrepreneur, journalist and activist)
4. [The ever-ongoing change in terminology](#terminology)
5. [Session 3: "Caste, Privacy, and digital technologies"](#session-3) Panellists - Nikita Sonavane (Lawyer and co-founder of the Criminal Justice and Police Accountability) and Manoj Mitta (Author, Caste Pride: Battles for equality in Hindu India)
6. [Birth related demographic data sufficient in caste survey?](#caste-census)

<section id="session-1">
<h2>The non-artificial consequences of AI
Moderated by Shivangi Narayan (researcher at AGOPOL) and Samarth Bansal (Independent journalist, writer, and coder)</h2>
</section>

A major point of contention amongst the panellists was the impact of biases involved in constructing artificial intelligence systems. The panellists discussed how there was a divide amongst the technical and the ethical aspects of artificial intelligence. It emerged from the discussion that these biases were not capable of expression in the form of algorithms. And while it was also argued that having an approximately foolproof system would dispel the problem of biases, I donâ€™t think it was compelling enough since the impact of an error in criminal justice systems is not minuscule. Samarth also stated two foremost modalities of artificial intelligence, the first being emergent abilities, and the second being alignment. 

**Prejudices in crime reporting**

This was a crucial topic in the first session where the impact of prevalent caste prejudices amongst different sections of the criminal justice system was highlighted. This included the prejudice that exists at the most basic level of data collection or crime reporting. We, as a society with caste seeped into its psyche, are more likely than not going to behave in a very discriminatory manner without realizing when interacting at the point of data entry with law enforcement. In a way, this highlights that the prejudice will be very difficult to eliminate from Artificial Intelligence enabled criminal justice systems. 

The definition of crime itself involves violence inflicted by the oppressor castes on the oppressed. This is apparent from the data available with the National Crime Records Bureau. 

It was also implicit towards the end of the conversation that algorithmic transparency was not possible, while it was mentioned in the discussion with the audience that we need to examine who owns the data being created, it being decided by experts in the field. 

<section id="thoughts-1">
<h2>Thoughts on how emergent abilities of AI "emerge"</h2>
</section>

The above two points refer to the power of epistemic communities to shape the world we live in. For instance, the scholars of artificial intelligence ethics have only themselves to contain their perceived errors, existing as they do in a highly specialized field with knowledge flowing through existing power hierarchies and possibly being affected by caste and the other very same identity markers that create biases. It is then necessary for policymakers to involve ethics scholars in their deliberations and mechanisms transparently. This takes the power to decide the future of which "emergent abilities" materialize outside the control of corporations which are essentially autonomous in deciding the future of an extremely powerful technological advancement. 

The requirement of transparency also emerged as a key concern in the next session titled,

<section id="session-2">
<h2>"How public are digital public infrastructures?"
Moderated by Aditi Agrawal (independent technology journalist) and the panellists were Mansi Kedia (Senior Fellow at ICRIER), Rohit Kumar (Founding partner at the Quantum Hub), Nikhil Pahwa (Entrepreneur, journalist and activist)</h2>
</section>

The moderator began by introducing the definition of digital public infrastructures as given by the Bill and Melinda Gates foundation. I found this definition on an article by the aforementioned organization: *"DPI is a digital network that enables countries to safely and efficiently deliver economic opportunities and social services to all residents. DPI can be compared to roads, which form a physical network that connects people and provides access to a huge range of goods and services."*

There was initially some difficulty on part of the panel to arrive at an understanding about the scope. An audience member also talked about the previous terminology that had existed in public discourse prior to the current naming as "Digital Public Infrastructure".

<section id="terminology">
<h2>Change in terminology</h2>
</section>

The changing terminology in policy documents and initiatives can also be indicative of different groups in different eras of the development of technology, using terminologies that suit the purpose of their developmental paradigms. However, the constant change between the terms used to describe industrial and technical frameworks can lead to ambiguity. For instance, in the case of "digital public infrastructure", the struggle to arrive at a definition is ongoing. ([See this attempt by the ORF](https://www.orfonline.org/research/defining-the-digital-public-infrastructure-approach/) to arrive at a definition of DPI which mentions "participatory government frameworks" whereas the [Bill and Melinda Gates Foundation characterizes the entirety of it as a "digital network"](https://www.gatesfoundation.org/ideas/articles/what-is-digital-public-infrastructure)). Evidently, this led to the adoption of the ["G20 Framework for systems of digital public infrastructure"](https://www.g20.org/content/dam/gtwenty/gtwenty_new/document/G20_Digital_Economy_Outcome_Document_and_Chair's_Summary_19082023.pdf) as part of the "Outcome Document" at the Digital Economy Ministers Meeting.

Eventually, the discussion steered to one of the administrative nature of regulating corporations in the digital public infrastructure, at least as regards to the payment systems regulated by entities. Payment system entities such as the National Payments Corporation of India being private companies that however, regulate public infrastructures emerged as a concern. An example of the consequence of this being non-public was the right to information jurisdiction, which regrettably does not extend to private companies.

The competition law consequences of a regulating entity being administered by the same sovereign that brings out a payments method such as BHIM also came up for discussion. And while the transnational network effects were brought up by Mansi, it was not clear as to how standardization amongst engineering and legal frameworks that operate alongside e-commerce platforms such as ONDC in the 'Digital public infrastructure', are being incorporated in the Indian iteration of digital public infrastructure.

**Standards - technical and legal**

There are pre-existing standards that may have to be adopted alongside digital public infrastructure that regulate engineering and provide guidelines for the development of systems and their administration. For instance, there are [core principles laid down by the Bureau of International Standards for "systematically important payment systems"](https://www.bis.org/cpmi/publ/d43.pdf) principle 10 of which is implied to include transparency in governance of payment systems. These principles have been promulgated in 2001 and can effectively be used as a yardstick for measuring transnational concordance amongst payment systems in the digital public infrastructure.

<section id="session-3">
<h2>Session 3: "Caste, Privacy, and digital technologies"
Panellists - Nikita Sonavane (Lawyer and co-founder of the Criminal Justice and Police Accountability) and Manoj Mitta (Author, Caste Pride: Battles for equality in Hindu India)</h2>
</section>

The "castelessness" or relative caste mobility amongst the Varnas in Hindu society projected by the upper castes was a central theme of this discussion. Manoj discussed how the "Guna-Karma" idea of rebirth according to virtues in previous lives betrays even Hindu nobility as it prevented the Maratha King "Chhatrapati" Shivaji from asserting the claim to his title due to Brahminical order in the day not allowing it. This has been written about in Manoj's book, "Caste Pride: Battles for equality in Hindu India" as well.

The session was built around a discussion involving historical data ranging from the privy council decisions in the 1850s to the recent Patna High Court decision on the caste census. Colonial prejudices and data collection on criminal tribes such as the listing of "thugees" by their physical and behavioral characteristics was pointed out by Nikita. This pointed to the fact that the data and the mechanisms for collecting data in a prejudicial manner were always there, however, with artificial intelligence, the problem of bias creeping into larger systemic effects is to be watched out for.

Questions were raised regarding the end of the census because of the availability of data collection from birth. This presumably refers to the goal of hundred percent Aadhaar adoption which through its demographic data collection is thought to eliminate the need for caste census. Nikita responded to this by stating, amongst others, that data collection entrenched structures of power, and that it obfuscates what is happening.

<section id="caste-census">
<h2>Birth related demographic data sufficient in caste survey?</h2>
</section>

This question also relates back to the points raised by the speakers earlier regarding caste mobility. This would indicate that mere birth and death data collection is not sufficient to collect data in a way that captures the demographic factors. Further, to add to what Nikita said about the obfuscation of data collection, one can also see it as a policy move that serves its own discursive as well as functional purposes that can be refined in addition to the now-ubiquitous birth data records. For instance, people responding to a caste census can also provide information that is not just demographic in categorization. The caste census in Bihar has a total of 17 heads including caste as one of them. There will be other human development markers collected as well, that can in due course be separated from an all-encompassing database such as the Aadhar with a different body entrusted with the survey in the future such as the Bihar State Backward Classes Commission also being a different data fiduciary with its own tailored policies to suit these purposes.

---
title: ICAT - A pipeline to generate (and annotate) contracts datasets. 
feature_text: |
   Collaboratively generating a database of "Indian Contracts in Adjudicated Texts".
excerpt: |
  "... <i>I figured that a <u> data extraction pipeline </u> that collects this data which is in the <u> public domain </u> and demonstrates how this can be done <u> openly </u> would be beneficial, hence - ICAT </i>... <br>... Version 1 is a sample of what expert annotation can look like for business cases that involve more specification..."
date: 2024-06-29
categories: 
  - Datasets
  - Legal Tech
  - AI
  - Currently working
---
Table of Contents:
<ol>
<li> <a href = "#Section1"> How it began? </a> </li>
<li> <a href = "#Section2"> Why collaboration? </a> </li>
<li> <a href = "#Section3"> The full feature set in development </a> </li>
<li> <a href = "#HFSpace"> A tool to query and add more data to the dataset </a> </li>
</ol>


<section id = "Section1">
<h3>How it began? </h3>
</section>

<p> When I began venturing into Legal Tech development, I knew that there is a strong hold of publishers over vast troves of legal data. Be it forms or precedents, judgment or statute, legal information has not been democratised the way it should have (at least for a field that so direly depends on the knowledge of all parties of "the law").
<br>
<br>
At the same time, I noticed that there is a large swathe of data that is in the public domain - that you can find in courts' judgments which serves the dual purpose of figuring out whether the matter discussed in the judgment is legally tenable and also as a source of the kind of text that can lead to that data.
<br>
<br>
Collecting data for AI/ML use cases is particularly important in a time when everyone is racing to build a Legal Tech solution, that in nearly all cases, relies on data. </p>

<div style="margin-left: 20px;"> 
        <h4><i>I figured that a <u> data extraction pipeline </u> that collects this data which is in the <u> public domain </u> and demonstrates how this can be done <u> openly </u> would be beneficial, hence - ICAT </i></h4>
    </div>

<section id = "Section2">
<h3> Why collaboration? </h3>
</section>
<p>
The ICAT pipeline is an interactive process that identifies user needs.
<br>

Because, learning is a two-way process - I am collecting responses to see what people need and giving them free inferencing on a model trained on an annotated dataset. 
<br>

It is hoped that as time passes, more people will add their queries, and hopefully give insights or feedback on what they expect to be annotated. 
</p>

<section id = "Section3">
<h3> The full feature set in development</h3>

1. Firstly, the dataset is available for anyone who wishes to train and inference it for their uses. It is shared under a Creative Commons - Attribution - ShareAlike License 4.0 under which you are mandated to similarly share any application which you develop using this.
<br>
Version 1 of this dataset is currently hosted on Hugging Face at the following link - <a href = "https://huggingface.co/datasets/schematise/ICAT-version1">https://huggingface.co/datasets/schematise/ICAT-version1</a> 
<br>
<br>
2. There is a <a href = "#HFSpace">public HuggingFace Space which contains an option to run a query pipeline that adds the results (Anonymously) to a relational database </a>. You can even download this space and see what the automated pipeline for collecting data looks like. 
<br>
<br>
3. If you like the dataset and/or query pipeline, you can view the <a href = "https://deepnote.com/workspace/mutaabik-bb27ba89-ef3a-49de-b973-2fca2f4c74b7/project/ICAT-Beta-90d69f02-b39a-4259-98fa-d4c4ad7d7557/notebook/Notebook%201-8b7b316e2a394f56ae2b43e06e1530f1"> data analytics platform hosted on DeepNote </a>. This is essentially a notebook that I will be adding insights to periodically for public viewing. 

</section>

<h4> Roadmap for the future? </h4>

- Version 1 is a sample of what expert annotation can look like for business cases that involve more specification. To this end, I will be gauging response and publishing a contracts dataset as far as possible.
- Contract similarity search from the eventually aggregated and ultimately annotated database.
- Adding annotations, such as sentiments, ontological mapping, chatting with the dataset. Hence, for example, segregating portions of the contractual clauses on the basis of the legal predicates that govern their legality could be generated via an ontology, which I'm looking to convert documents to in an automated manner in <a href = "https://github.com/sankalpsrv/Schematise"> my other projects. </a>

<section id = "HFSpace">
<h3> A pipeline for automated database generation (BETA) </h3>
</section>
<iframe
	src="https://schematise-icat-query-database-beta.hf.space"
	frameborder="0"
	width="850"
	height="450"
></iframe>



